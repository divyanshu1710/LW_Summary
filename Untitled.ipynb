{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85f35ed8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'IAudioEndpointVolume' has no attribute 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#accessing the speakers using pycaw\u001b[39;00m\n\u001b[0;32m     22\u001b[0m devices \u001b[38;5;241m=\u001b[39m AudioUtilities\u001b[38;5;241m.\u001b[39mGetSpeakers()      \u001b[38;5;66;03m#retrieves the collection of audio devices, specifically the speakers\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m interface \u001b[38;5;241m=\u001b[39m devices\u001b[38;5;241m.\u001b[39mActivate(\u001b[43mIAudioEndpointVolume\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m, CLSCTX_ALL, \u001b[38;5;28;01mNone\u001b[39;00m)      \u001b[38;5;66;03m#Activate() method is called on the speakers to activate the audio endpoint volume control interface. It takes three arguments: the interface identifier \u001b[39;00m\n\u001b[0;32m     26\u001b[0m volume \u001b[38;5;241m=\u001b[39m cast(interface, POINTER(IAudioEndpointVolume))     \u001b[38;5;66;03m#cast() function is used to convert the interface object to a pointer of type \u001b[39;00m\n\u001b[0;32m     27\u001b[0m                                                             \u001b[38;5;66;03m#IAudioEndpointVolume. It allows you to access the methods and properties of the IAudioEndpointVolume interface.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# finds the volume range between the minimum and maximum volume. We place it outside the while loop because we need to find the volume range once.\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'IAudioEndpointVolume' has no attribute 'id'"
     ]
    }
   ],
   "source": [
    "import cv2      #library for image\n",
    "import mediapipe as mp  #tasks like hand tracking, pose estimation, object detection, and more. \n",
    "from math import hypot  #hypot - returns the Euclidean norm (distance from the origin to the coordinates given)\n",
    "from ctypes import cast, POINTER    #enable you to define the necessary data types, call functions from shared libraries, pass data between Python and C, and handle error conditions.\n",
    "from comtypes import CLSCTX_ALL     \n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "#connect to the default camera\n",
    "cap = cv2.VideoCapture(0)   \n",
    "\n",
    "\n",
    "#initialize mediapipe hands\n",
    "mp_Hands = mp.solutions.hands   #detect the landmarks of the hands in an image\n",
    "hands = mp_Hands.Hands()\n",
    "mp_Draw = mp.solutions.drawing_utils       # functions for visualizing and drawing landmarks\n",
    "\n",
    "\n",
    "#accessing the speakers using pycaw\n",
    "devices = AudioUtilities.GetSpeakers()      #retrieves the collection of audio devices, specifically the speakers\n",
    "\n",
    "interface = devices.Activate(IAudioEndpointVolume.id, CLSCTX_ALL, None)      #Activate() method is called on the speakers to activate the audio endpoint volume control interface. It takes three arguments: the interface identifier \n",
    "\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))     #cast() function is used to convert the interface object to a pointer of type \n",
    "                                                            #IAudioEndpointVolume. It allows you to access the methods and properties of the IAudioEndpointVolume interface.\n",
    "\n",
    "\n",
    "# finds the volume range between the minimum and maximum volume. We place it outside the while loop because we need to find the volume range once.\n",
    "volMin, volMax = volume.GetVolumeRange()[:2]       # [:2] , it selects the first two elements of the iterable returned by volume.GetVolumeRange().\n",
    "\n",
    "\n",
    "#capturing an image from the camera\n",
    "while True:                            #allows for continuous processing of frames.\n",
    "    status, image = cap.read()        #status indicates whether the frame was successfully read, and image contains the captured frame data.\n",
    "    imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)   # converts the color space of the captured frame from BGR (Blue-Green-Red) to RGB (Red-Green-Blue).\n",
    "    results = hands.process(imageRGB)       # performs hand detection on the image and returns the results, which may include the detected hand landmarks, gestures, or other relevant information.\n",
    "\n",
    "\n",
    "#check if there are multiple hands in the input\n",
    "lmlist = []\n",
    "if results.multi_hand_landmarks:                    #creates an empty list that will store the list of elements of the hands detected by the mediapipe hand module\n",
    "    \n",
    "    #create loop for multiple hands\n",
    "    for handlandmark in results.multi_hand_landmarks:          #allows accessing each individual hand's landmarks.\n",
    "        for id, lm in enumerate(handlandmark.landmark):        #iterates over the landmarks within each detected hand. It assigns an index (id) and the landmark object (lm) to each iteration.\n",
    "            h, w, c = image.shape                              # retrieves the height (h), width (w), and number of channels (c) of the image captured from the video source.\n",
    "            cx, cy = int(lm, x*w), int(lm.y*h)                 #calculates the pixel coordinates (cx, cy) of the current landmark (lm) by multiplying the normalized landmark coordinates (lm.x, lm.y) with the width and height of the image, respectively. The coordinates are then converted to integers.\n",
    "            lmlist.append([id, cx, cy])                        #used to store and process the landmark information.    \n",
    "        mp_Draw.Draw_landmarks(image, handlandmark, mp_Hands.HAND.CONNECTIONS)      #draws the landmarks and connections on the image\n",
    "\n",
    "\n",
    "\n",
    "#Specifying the points of the thumb and middle finger \n",
    "if lmList != []:                            #checks if the lmList is not empty as lmList is assumed to be a list containing hand landmark information.\n",
    "    x1, y1 = lmList[4][1], lmList[4][2]     # assigns the x-coordinate (x1) and y-coordinate (y1) values of the landmark at index 4 to variables x1 and y1, respectively. \n",
    "    x2, y2 = lmList[8][1], lmList[8][2]     #assigns the x-coordinate (x2) and y-coordinate (y2) values of the landmark at index 8 to variables x2 and y2, respectively.\n",
    "\n",
    "\n",
    "\n",
    "#Drawing a circle between the tip of the thumb and the tip of the index finger     \n",
    "cv2.circle(img, (x1, y1), 15, (255, 0, 0), cv2.FILLED)      #draws a filled circle on the img image using the cv2.circle() function. #cv2.FILLED parameter specifies that the circle should be filled rather than just an outline.\n",
    "                                                            #circle is centered at the coordinates (x1, y1) and has a radius of 15 pixels. \n",
    "                                                            #The (255, 0, 0) tuple represents the color of the circle in BGR format, where (255, 0, 0) corresponds to blue.\n",
    "cv2.circle(img, (x2, y2), 15, (255, 0, 0), cv2.FILLED)      #draws another filled circle on the img image. \n",
    "\n",
    "\n",
    "#Drawing a line between points 4 and 8\n",
    "cv2.line(img, (x1, y1), (x2, y2), (255, 0, 0), 3)       #draws a line on the img\n",
    "                                                        #connects two points: (x1, y1) and (x2, y2). \n",
    "                                                        #The (255, 0, 0) tuple represents the color of the line in BGR format, where (255, 0, 0) corresponds to blue. \n",
    "                                                        #The 3 parameter specifies the thickness of the line in pixels.\n",
    "\n",
    "\n",
    "\n",
    "#Finding the distance between points 4 and 8\n",
    "length = hypot(x2 - x1, y2 - y1)                         #calculated value of the hypotenuse, which represents the distance between the two points\n",
    "\n",
    "\n",
    "#Converting the hand range to the volume range\n",
    "vol = np.interp(length, [15, 220], [volMin, volMax])    # this interpolate the length value. # Interpolation is a method for estimating values within a given range based on known data points.\n",
    "                                                        #[15, 220] represents the range of hand measurements\n",
    "print(vol, length)                        \n",
    "\n",
    "\n",
    "\n",
    "#setting the master volume\n",
    "volume.SetMasterVolumeLevel(vol, None)                  # there is no specific output device specified for the volume control.\n",
    "\n",
    "\n",
    "\n",
    "#Displaying the video output used to interact with the user\n",
    "cv2.imshow('Image', image)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "cv2.waitKey()                      #it means 0.1 second it means we are clicking photograph 10 times in 1 second\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3783f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf in c:\\users\\91800\\anaconda3\\lib\\site-packages (3.19.1)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-4.23.3-cp39-cp39-win_amd64.whl (422 kB)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.1\n",
      "    Uninstalling protobuf-3.19.1:\n",
      "      Successfully uninstalled protobuf-3.19.1\n",
      "Successfully installed protobuf-4.23.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mediapipe 0.10.0 requires protobuf<4,>=3.11, but you have protobuf 4.23.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "055ecbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycaw\n",
      "  Downloading pycaw-20230407-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\91800\\anaconda3\\lib\\site-packages (from pycaw) (5.8.0)\n",
      "Requirement already satisfied: comtypes in c:\\users\\91800\\anaconda3\\lib\\site-packages (from pycaw) (1.1.10)\n",
      "Installing collected packages: pycaw\n",
      "Successfully installed pycaw-20230407\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pycaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f101856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
