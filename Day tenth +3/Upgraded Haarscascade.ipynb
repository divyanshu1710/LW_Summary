{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897d8edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "\n",
    "# Load the Haar Cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Constants for distance measurement\n",
    "KNOWN_DISTANCE = 100  # Define a known distance (in cm) from the camera to the face\n",
    "KNOWN_FACE_WIDTH = 15  # Define the width of the face (in cm) at the known distance\n",
    "\n",
    "while True:\n",
    "    # Read the frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Process each detected face\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Calculate the distance to the face using the known distance and face width\n",
    "        face_width_pixels = w\n",
    "        distance = (KNOWN_FACE_WIDTH * cap.get(3)) / (2 * face_width_pixels * math.tan(cap.get(4) * math.pi / 360))\n",
    "        \n",
    "        # Draw the distance on the frame\n",
    "        cv2.putText(frame, f\"Distance: {distance:.2f} cm\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame with distance information\n",
    "    cv2.imshow('Distance Measurement', frame)\n",
    "\n",
    "    # Exit the loop if the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71007833",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 2 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# Overlay the accessory on the face region\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m---> 34\u001b[0m         frame[y1:y2, x1:x2, c] \u001b[38;5;241m=\u001b[39m accessory_resized[:, :, c] \u001b[38;5;241m*\u001b[39m (\u001b[43maccessory_resized\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m) \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m     35\u001b[0m                                   frame[y1:y2, x1:x2, c] \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m accessory_resized[:, :, \u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Display the frame with accessories added\u001b[39;00m\n\u001b[0;32m     38\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccessory Addition\u001b[39m\u001b[38;5;124m'\u001b[39m, frame)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 2 with size 3"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the Haar Cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Load the accessory image with alpha channel\n",
    "accessory_img = cv2.imread('sunglasses.jpeg', cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "while True:\n",
    "    # Read the frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Process each detected face\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Resize the accessory image to match the size of the detected face\n",
    "        accessory_resized = cv2.resize(accessory_img, (w, h))\n",
    "\n",
    "        # Calculate the coordinates to overlay the accessory on the face\n",
    "        x1 = x\n",
    "        y1 = y - int(h / 2)\n",
    "        x2 = x1 + w\n",
    "        y2 = y1 + h\n",
    "\n",
    "        # Overlay the accessory on the face region\n",
    "        for c in range(3):\n",
    "            frame[y1:y2, x1:x2, c] = accessory_resized[:, :, c] * (accessory_resized[:, :, 3] / 255.0) + \\\n",
    "                                      frame[y1:y2, x1:x2, c] * (1.0 - accessory_resized[:, :, 3] / 255.0)\n",
    "\n",
    "    # Display the frame with accessories added\n",
    "    cv2.imshow('Accessory Addition', frame)\n",
    "\n",
    "    # Exit the loop if the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c0cef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef7824",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
